\documentclass{article}  
\author{Roger Zou, Julia Ni}  
\date{\today}  
\title{Alignment of EM sections}  
 
\usepackage[margin=0.7in]{geometry}
\usepackage{amsthm,amssymb,amsfonts}
\usepackage[fleqn]{amsmath}
\usepackage{mathtools}
\usepackage{multicol}
\usepackage{tikz}
\usepackage{enumitem}
\usetikzlibrary{arrows,positioning,automata, shapes}
\usepackage{graphicx}
\graphicspath{ {imgs/} }
\usepackage{wrapfig}
\usepackage[]{algorithm2e}

\begin{document}  
\maketitle

\section{Overview}
Alignment of 3D electron microscope sections with CAJAL-3D API integration. Its use is domain-specific; namely, the program corrects for translations and rotations between image slices.  See the README for details about the functions available to the user. This report aims to provide details on the methods and techniques used to achieve the desired outcome. The main concept of this program is using cross-correlation to determine rotatio and translation parameters that maximizes the correlation between pairwise images. This core technique is extended to provide scalable global alignment of terobytes of EM image data with further optimization and error checking steps for robustness, detailed below.

\section{Global Pairwise Alignment}
Before an entire 3D image cube can be aligned completely, we first must compete alignment between pairs of images. 
Computes the pairwise alignment between adjacent two images in an image cube. Optionally first uses feature matching to determine the rotation parameter between two images. Then uses 2D Cross-Correlation to refine the rotation parameter and determine the translation parameters.

\subsection{Feature Matching}
\begin{enumerate}
\item gaussian blur, then downsample (imresize). Also tried median filtering and anisotropic diffusion without characterizable improvement.
\item detect SURF features (experimented with most feature detectors in matlab, but SURF appeared to work the best)
\item match the features and estimate the rotation parameter
\item save the rotation angle and apply rotation to image for input to 2D cross-correlation step.
\end{enumerate}
\textbf{Problems:} effectiveness decreases for images that are more dissimilar. When images have noise and blemishes, it struggles to identify any features at all, or the matches are spurious. Not using this step doesn't seem to make much of a difference right now. \\
\textbf{Improvements:} Are there ways of using entire cell structure features (such as entire mitochondria and other organelles) to use for feature matching? This is how it appears some humans (or at least how I) visually align these EM sections. The current method isn't that useful, but by incorporating these features I feel like it has the potential to be much better.

\subsection{2D Cross-Correlation}
Iterate through image stack, and apply the following procedure to each adjacent pair of images. \\
\textbf{Alignment with Cross-Correlation Procedure:}
\begin{enumerate}
\item apply hamming window to both images
\item take DFT, then high-pass filter, then resample in log-polar coordinates
\item compute phase correlation to find best rho (scaling) and theta (rotation angle)
\item refine initial rotation parameter (computed from feature matching previously) by using the theta value from correlation
\item rotate the image appropriately, then compute normalized cross correlation to find translation parameters
\item use support vector machine to identify peak in the cross correlation matrix of images that accurately correspond to the actual translation parameters
\item save pairwise affine transformation matrix
\end{enumerate}

The time complexity is $O(nlogn)$, where $n$ is the the number of voxels. The upper bound is because of the Fast Fourier Transform computations. The space complexity is linear to the number of voxels. One optimization step is scaling the image stack before determining image transforms. Scaling between 0.5 and 1 does not appear to have much of an effect on alignment quality. Scaling by 0.5 effectively decreases the constant in front of $nlogn$ in the running time by 4. \\

\textbf{Problems:} For images that are more dissimilar, identifying the rotation parameter is a challenge; The rotation identified is often close to the true rotation, but not close enough (see bottom). For most image inputs, it appears that rotations are small to begin with, so this usually isn't a problem. However, the problem sometimes occurs when I artificially add large rotations to image inputs before alignment.\\
\textbf{Improvements:} Are there better ways to identify the rotation angle needed to align images? Are there ways to improve the correlation strength? Some humans (or at least I) match outlines of noticeable cell structures. High-pass filtering ideally helps, but the noise and blemishes would probably pass through as well. One idea: selectively darken regions that we don't want to matter as much in the correlation? \\

\subsubsection{Peak Detection}

Uses a SVM to classify a local maxima as a peak or non peak. 
Simply picking the maximum values will not always work, as the example on the right demonstrates. The peak is quite obvious, but the maximum values (in red) are clustered elsewhere. The SVM is trained with shape features, and performs the best compared to other methods.\\
Attempted Methods to find peaks in the cross correlation of two images:

\begin{enumerate}
\item Identifying maximum values. However, this won't always work, as the example on the right demonstrates.
\item Correlating the cross correlation of two images with a normal distribution. This is attempting to factor in shape. In theory this should accentuate the true peaks, but this won't always work because artificial peaks may be introduced. Another problem is that this method is quite slow, because it has to perform more cross correlation procedures. 
\item Support Vector Machine trained on 5 features: number of pixels in image, area of binary thresholded region, max gradient, max laplacian, and skewness of the histogram. The cross correlation images is divided into 9 subsections. The maximum is identified in each, and evaluated with the SVM. The maximum value predicted by the SVM to be a peak is labelled as the actual peak. If no maximum values are predicted by the SVM to be a peak, then no peak exists. This appears to work the best. It accurately identifies peaks even if not the global maximum and the running time is almost instantaneous.
\end{enumerate}

\subsection{Global Stack Alignment}
Uses the pairwise transformation parameters to compute global transformation parameters. Starts with the first image and builds the aligned stack iteratively. \\
\textbf{Problem:} One incorrect transformation causes the rest of the image stack to shift by the same amount. Is this the 'right' thing to allow happen? Also, how to deal with all black images? \\
\textbf{Improvements:} Other methods of putting all the aligned images together?

\subsubsection{Tune Transformation Parameters}
This attempts to improve the estimate of the rotation amount by minimizing an error function (usually mean squared error). This is also important because log-polar sampling to determine the best rotation parameter is discretized, which means the best rotation angle may not be available at the cross correlation step. Thus, this step iterates over a small range of rotation and translation parameters surrounding the original estimated parameters. It then picks the rotation angle and translation amount that minimizes the error function.

\subsubsection{Error Minimization}
The final (optional) step right now is to use image data outside a specific image pair to align the image pair. This works well by correcting alignments when one pairwise alignment fails for some reason. The specifics of the algorithm are below. The algorithm improves pairwise transformation parameters by computing pairwise transformations from other adjacent images. Different estimates of the transformation parameters between the image pair are computed. The transformation parameter that minimizes an error function is selected. \\
	\begin{algorithm}
	\DontPrintSemicolon
	\textbf{Transform Update/Error Minimization}\\
	\KwIn{4 adjacent images:$M1,M2,M3,M4$, and table of pairwise transformations and associated error.}
	\KwOut{$T_{2,3}^{*}$, the transformation matrix to align $(M2, M3)$ that minimizes error function $e_{2,3}^{*}$}
	Let $T_{2,3}$ be the transformation matrix to align $M2, M3$, and $e_{2,3}$ be the associated error.\\
	1) Compute $T_{1,3}$ and $T_{2,4}$.\\
	2) We wish to find $T_{2,3}^{*}$ that minimizes $e_{2,3}^{*}$ by using $T_{1,3},T_{2,4}$.\\
	3) Let $T_{2,3}^{*} = [T_{1,3}^{-1}*T_{1,2}]x_1 + [T_{2,4}*T_{3,4}^{-1}]x_2 + [T_{2,3}]x_3 + [I]x_4$\\
	Note that $T_{1,3}^{-1}*T_{1,2}$ and $T_{2,4}*T_{3,4}^{-1}$ are two other estimates of $T_{2,3}$.\\
	Let $e_{1,2,3}$ be the error from aligning with $T_{1,3}^{-1}*T_{1,2}$, $e_{2,3,4}$ be the error from aligning with $T_{2,4}*T_{3,4}^{-1}$.\\
	Let $e_i$ be the error from not aligning (using identity matrix $I$) \\
 	4) Pose the following equation and constraints:
	\begin{align*}
	 \text{minimize: } z &= e_{1,2,3}x_1 +  e_{2,3,4}x_2 + e_{2,3}x_3 + e_ix_4\\
	 \text{constraints: }&x_1 + x_2 + x_3 + x_4 = 1\\
	 &x_1, x_2, x_3, x_4 \ge 0
	\end{align*}
	5) Solve to find $x_1, x_2, x_3, x_4$.\\
	6) \textbf{return} $T_{2,3}^{*}$ by plugging $x_1, x_2, x_3, x_4$ into $[T_{1,3}^{-1}*T_{1,2}]x_1 + [T_{2,4}*T_{3,4}^{-1}]x_2 + [T_{2,3}]x_3 + [I]x_4$
	\end{algorithm}
	
\textbf{Problems:} None that I know of :-)\\
\textbf{Improvements:} Other optimization parameters to add? Other constraints that can help to minimize error? Can't think of anything specific at the moment.
\end{document}
