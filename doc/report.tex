\documentclass{article}  
\author{Roger Zou, Julia Ni}  
\date{\today}  
\title{Alignment of Electron Microscope Sections}  
 
\usepackage[margin=1.0in]{geometry}
\usepackage{amsthm,amssymb,amsfonts}
\usepackage[fleqn]{amsmath}
\usepackage{mathtools}
\usepackage{multicol}
\usepackage{tikz}
\usepackage{enumitem}
\usetikzlibrary{arrows,positioning,automata, shapes}
\usepackage{graphicx}
\graphicspath{ {imgs/} }
\usepackage{wrapfig}
\usepackage[]{algorithm2e}

\begin{document}  
\maketitle

\section{Overview}
Alignment of 3D electron microscope (EM) sections with CAJAL-3D API integration. Its use is domain-specific; namely, the program corrects for translations and rotations between image slices. See the README for details about the functions available to the user. The program primarily uses cross-correlation to determine rotation and translation parameters which maximize the correlation between pairwise images. This report provides details on such alignment methods, and extends the aforementioned core technique to provide scalable global alignment of terobytes of EM image data while including additional optimization and error-computation steps for robustness; see below. Future implementation of said method in the connectome estimation pipeline and the Open Connectome Project may also be possibilities. 

\section{Global Pairwise Alignment}
Before an entire 3D image cube can be aligned globally, we must compute alignment between pairs of images using cross-correlation.
\\
Median filtering and histogram equalization, which are performed before sampling in log-polar coordinates in the Fourier domain, detect the shifts in rho and theta (scale and rotation, respectively). This method determines the best rotation required to align pairwise images. Next, we use normal cross-correlation to determine the best translational shift. See the '2D Cross-Correlation' section for more information.
\\
One important step in the cross-correlation process is identifying the transformation parameters from the cross-correlation of two images. The correct transformation between two images is determined by finding the 'correct' peak in their cross-correlation. However, since problems arise when the 'correct' peak is NOT the maximum value, we use a trained support vector machine (SVM) classifier to determine the correct peak among potential candidate peaks. See the 'Peak Detection' section for more information. 

\subsection{2D Cross-Correlation}
Iterate through image stack, and apply the following procedure to each adjacent pair of images. \\
\textbf{Alignment with Cross-Correlation Procedure:}
\begin{enumerate}
\item Apply hamming window to both images. 
\item Take the Discrete Fourier Transform (DFT), apply a high-pass filter, and then resample the images in log-polar coordinates. 
\item Compute the phase correlation to find the best rho (scaling) and theta (rotation angle). 
\item Refine the initial rotation parameter, previously computed from feature matching, by using the theta value from correlation. 
\item Rotate the image appropriately, then compute normalized cross-correlation to find translation parameters. 
\item Use an SVM to identify the peak in the cross-correlation matrix of images that accurately corresponds to the actual translation parameters.
\item Save the pairwise affine transformation matrix. 
\end{enumerate}The time complexity is $O(nlogn)$, where $n$ is the the number of voxels. This upper bound arises due to the Fast Fourier Transform (FFT) computations. The space complexity is linear to the number of voxels. One optimization step is scaling the image stack before determining image transforms. Scaling between 0.5 and 1 does not appear to have much of an effect on alignment quality while scaling by 0.5 effectively decreases the constant in front of $nlogn$ in the running time by 4. \\

\subsection{Peak Detection}
Uses an SVM to classify a local maxima as a peak or non-peak. 
Picking only the maximum values will not always yield the correct results, as the example on the right demonstrates. The peak is quite obvious, but the maximum values (in red) are clustered elsewhere. The SVM is trained with shape features to distinguish between peaks and non-peaks, and performs the best compared to other methods.\\

\textbf{Attempted Methods to find peaks in the cross correlation of two images}
\begin{enumerate}
\item Identify maximum values. However, this will not always work, as the example on the right shows.
\item Correlate the cross-correlation of two images with a normal distribution. In theory this should accentuate the true peaks, since it takes into account the shape of all possible peaks, but this won't always produce the desired results because artificial peaks may be introduced. Another problem is that this method is quite slow because it has to perform more cross-correlation procedures. 
\item Use an SVM trained on five features: number of pixels in image, area of binary thresholded region, maximum gradient, maximum Laplacian, and skewness of the histogram. The cross-correlation images are divided into nine subsections. The maximum is identified in each, evaluated with the SVM, and then the maximum value predicted by the SVM to be a peak is labeled as the actual peak. If no maximum values are predicted by the SVM to be peaks, then no peak exists. This appears be the best method as it accurately identifies peaks which are not the global maxima and its run time is nearly instantaneous. 
\end{enumerate}

\section{Unused, Functional Code}
\subsection{RANSAC}
Originally implemented to detect folds in the images and subsequently help split images into pieces to aid in alignment process. We have not encountered any thus far, so this functionality was never included in our pipeline.
\subsection{SURF Feature Matching}
Originally used to correct large rotations before aligning with cross-correlation. Eventually discarded because images are often too different to match features well. Downsampling did not help much for some images.\\
\begin{enumerate}
\item Use Gaussian blur and then downsample (via MATLAB's $imresize$). Also tried median filtering and anisotropic diffusion without characterizable improvement.
\item Detect SURF features (experimented with most feature detectors in MATLAB, but SURF appeared to work the best). 
\item Match the features and estimate the rotation parameter.
\item Save the rotation angle and apply the rotation to image for input to 2D cross-correlation step.
\end{enumerate}
\textbf{Problems:} Effectiveness decreases for more dissimilar images. SURF also struggles to identify features or makes spurious matches when there are noise and blemishes in the images. This step does not seem to lead to drastic improvements. \\
\textbf{Improvements:} Are there ways of using entire cell structure features such as whole mitochondria and other organelles for feature matching? This is how it appears some humans (or at least how I) visually align these EM sections. The current method isn't that useful, but by incorporating these features I feel like it has the potential to be much better.

\section{Global Stack Alignment}
Uses the pairwise transformation parameters to compute global transformation parameters. Starts with the first image and builds the aligned stack iteratively, taking into account the pairwise transformation between two images as well as the previous transformations of the previous images. Can also reverse alignment given an aligned stack of images, again using the iterative nature of alignment transformations. \\
\textbf{Problem:} One incorrect transformation causes the rest of the image stack to shift by the same amount. Is this the 'right' thing to allow happen? Also, how to deal with all black images? \\
\textbf{Improvements:} Other methods of putting all the aligned images together?

\subsection{Tune Transformation Parameters}
Attempts to improve the estimate of the rotation amount by minimizing an error function. While three different error metrics are available to determine 'accuracy' of alignment (peak-signal-to-noise ratio (PSNR), mean-squared error (MSE), and mean pixel intensity difference.), MSE is usually used. This step is important because log-polar sampling to determine the best rotation parameter is discretized so the 'best' rotation angle may not be available at the cross-correlation step. Here, the algorithm iterates over a small range of rotation and translation parameters surrounding the original estimated parameters, and then chooses the rotation angle and translation shift that minimize the error function.

\subsection{Error Minimization}
The final (optional) step right now is to use image data outside a specific image pair to align the image pair. This works well by correcting alignments when one pairwise alignment fails for some reason. The specifics of the algorithm are detailed below. The algorithm improves pairwise transformation parameters by computing pairwise transformations from other adjacent images. Different estimates of the transformation parameters between the image pair are computed from solving a linear programming problem. The transformation parameter that minimizes a particular error function is selected. \\

	\begin{algorithm}
	\DontPrintSemicolon
	\textbf{Transform Update/Error Minimization}\\
	\KwIn{4 adjacent images:$M1,M2,M3,M4$, and table of pairwise transformations and associated error.}
	\KwOut{$T_{2,3}^{*}$, the transformation matrix to align $(M2, M3)$ that minimizes error function $e_{2,3}^{*}$}
	Let $T_{2,3}$ be the transformation matrix to align $M2, M3$, and $e_{2,3}$ be the associated error.\\
	1) Compute $T_{1,3}$ and $T_{2,4}$.\\
	2) We wish to find $T_{2,3}^{*}$ that minimizes $e_{2,3}^{*}$ by using $T_{1,3},T_{2,4}$.\\
	3) Let $T_{2,3}^{*} = [T_{1,3}^{-1}*T_{1,2}]x_1 + [T_{2,4}*T_{3,4}^{-1}]x_2 + [T_{2,3}]x_3 + [I]x_4$\\
	Note that $T_{1,3}^{-1}*T_{1,2}$ and $T_{2,4}*T_{3,4}^{-1}$ are two other estimates of $T_{2,3}$.\\
	Let $e_{1,2,3}$ be the error from aligning with $T_{1,3}^{-1}*T_{1,2}$, $e_{2,3,4}$ be the error from aligning with $T_{2,4}*T_{3,4}^{-1}$.\\
	Let $e_i$ be the error from not aligning (using identity matrix $I$) \\
 	4) Pose the following equation and constraints:
	\begin{align*}
	 \text{minimize: } z &= e_{1,2,3}x_1 +  e_{2,3,4}x_2 + e_{2,3}x_3 + e_ix_4\\
	 \text{constraints: }&x_1 + x_2 + x_3 + x_4 = 1\\
	 &x_1, x_2, x_3, x_4 \ge 0
	\end{align*}
	5) Solve to find $x_1, x_2, x_3, x_4$.\\
	6) \textbf{return} $T_{2,3}^{*}$ by plugging $x_1, x_2, x_3, x_4$ into $[T_{1,3}^{-1}*T_{1,2}]x_1 + [T_{2,4}*T_{3,4}^{-1}]x_2 + [T_{2,3}]x_3 + [I]x_4$
	\end{algorithm}	

\textbf{Problems:} None that I know of :-)\\
\textbf{Improvements:} Other optimization parameters to add? Other constraints that can help to minimize error? Can't think of anything specific at the moment.
\end{document}
